# RepoTransBench: A Real-World Multilingual Benchmark for Repository-Level Code Translation

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://python.org)
[![Paper](https://img.shields.io/badge/Paper-arXiv-red.svg)](https://arxiv.org/pdf/2412.17744)

## ðŸ“– Overview

**RepoTransBench** is a comprehensive repository-level code translation benchmark featuring **1,897 real-world repository samples** across **13 language pairs** with automatically executable test suites. Unlike previous fine-grained benchmarks that focus on snippets, functions, or files, RepoTransBench addresses real-world demands where entire repositories need translation.

### Key Features

- ðŸŒ **Multilingual**: 13 translation pairs covering 7 programming languages (C, C++, C#, Java, JavaScript, Python, Rust, Matlab)
- ðŸ“Š **Large-scale**: 1,897 repository samples with comprehensive test coverage
- âš¡ **Execution-based**: Automatic test suites for functional correctness validation
- ðŸ—ï¸ **Real-world**: Repository-level complexity with dependencies, configuration files, and resource management
- ðŸ¤– **Automated**: Multi-agent framework for benchmark construction

### Supported Translation Pairs

| Source Language | Target Languages |
|----------------|------------------|
| C | Python, Rust |
| C++ | Python |
| C# | Java |
| Java | C#, Go, Python |
| JavaScript | Python |
| Matlab | Python |
| Python | C++, Go, Java, Rust |

## ðŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Docker (for sandboxed execution)
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/DeepSoftwareAnalytics/RepoTransBench.git
   cd RepoTransBench
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download the dataset**
   
   Download the benchmark data from our latest release:
   
   **[ðŸ“¥ Release: RepoTransBench Dataset v1.0](https://github.com/DeepSoftwareAnalytics/RepoTransBench/releases/tag/v1.0)**
   
   ```bash
   # Download and extract the dataset to /workspace directory
   mkdir -p /workspace
   cd /workspace
   wget https://github.com/DeepSoftwareAnalytics/RepoTransBench/releases/download/v1.0/repotransbench_dataset.tar.gz
   tar -xzf repotransbench_dataset.tar.gz
   ```

4. **Configure API access**
   ```bash
   # Add your API keys to the configuration file
   echo "api_key_1 your_openai_api_key_here" > RepoTransAgent/API_KEY.txt
   echo "api_key_2 your_anthropic_api_key_here" >> RepoTransAgent/API_KEY.txt
   ```

5. **Set up Docker environment (optional)**
   ```bash
   cd docker
   docker-compose up -d
   ```

## ðŸ“Š Benchmark Statistics

| Metric | Value |
|--------|-------|
| **Total Samples** | 1,897 |
| **Translation Pairs** | 13 |
| **Programming Languages** | 7 |
| **Average Tokens per Sample** | 23,966 |
| **Average Lines of Code** | 2,394 |
| **Average Functions** | 177 |
| **Average Classes** | 35 |
| **Average Import Statements** | 163 |
| **Line Coverage** | 81.89% |
| **Branch Coverage** | 72.61% |

## ðŸ¤– RepoTransAgent

We introduce **RepoTransAgent**, a general agent framework for repository-level code translation based on the ReAct (Reasoning + Acting) paradigm.

### Key Capabilities

- **ReadFile**: Examine code files, configurations, and documentation
- **CreateFile**: Generate translated files and configurations
- **ExecuteCommand**: Run builds, tests, and dependency installations
- **SearchContent**: Locate specific code patterns and dependencies
- **Finished**: Mark translation completion

### Quick Start with RepoTransAgent

1. **Single Project Translation**
   ```bash
   # Translate a single project
   python -m RepoTransAgent.run \
       --project_name "your_project_name" \
       --source_language "Python" \
       --target_language "Java" \
       --model_name "claude-sonnet-4-20250514" \
       --max_iterations 20
   ```

2. **Batch Translation**
   ```bash
   # Run batch translation on multiple projects
   python -m RepoTransAgent.run_batch
   ```

3. **Available Models**
   - `claude-sonnet-4-20250514` (default)
   - `gpt-4.1`
   - `gemini-2.5-flash-lite`
   - `deepseek-chat`
   - `qwen3-235b-a22b`

### Command Line Arguments

#### Single Translation (`RepoTransAgent.run`)
```bash
python -m RepoTransAgent.run \
    --project_name PROJECT_NAME \      # Required: Name of the project to translate
    --source_language SOURCE_LANG \    # Required: Source language (Python, Java, C++, etc.)
    --target_language TARGET_LANG \    # Required: Target language (Python, Java, C++, etc.)
    --model_name MODEL_NAME \          # Optional: LLM model (default: claude-sonnet-4-20250514)
    --max_iterations MAX_ITER          # Optional: Max iterations (default: 20)
```

#### Batch Translation (`RepoTransAgent.run_batch`)
```bash
python -m RepoTransAgent.run_batch
```
The batch script automatically:
- Reads from `/workspace/target_projects/projects_summary.jsonl`
- Processes multiple projects in parallel
- Supports resume functionality (skips completed projects)
- Saves detailed results and logs

## ðŸ“‹ Usage Examples

### 1. Basic Translation

```python
# Direct command line execution
python -m RepoTransAgent.run \
    --project_name "example_project" \
    --source_language "Python" \
    --target_language "Java" \
    --model_name "claude-sonnet-4-20250514"
```

### 2. Evaluation on Benchmark

```bash
# The agent automatically evaluates against tests during translation
# Results are saved in logs/ directory with detailed analysis

# Example log structure:
# logs/claude-sonnet-4-20250514/project_name_Python_to_Java_20240130_143022/
# â”œâ”€â”€ system_prompt.txt          # System prompt used
# â”œâ”€â”€ turn_01.txt                # Each conversation turn
# â”œâ”€â”€ turn_02.txt
# â”œâ”€â”€ ...
# â””â”€â”€ final_summary.txt          # Final results and test analysis
```

### 3. Batch Processing

```bash
# Run multiple projects in parallel (configurable in run_batch.py)
python -m RepoTransAgent.run_batch

# Configuration in run_batch.py:
# - max_per_pair: Projects per translation pair
# - num_processes: Parallel processes (default: 50)
# - max_iterations: Max iterations per project (default: 20)
```

## ðŸ“ˆ Evaluation Results

Our evaluation reveals that repository-level code translation remains challenging:

| Method | Success Rate | Compilation Rate |
|--------|-------------|------------------|
| Translation Only | 0.0% | 26.2% |
| Error Feedback | 12.4% | 30.5% |
| **RepoTransAgent** | **32.8%** | **54.8%** |

### Key Findings

1. **Directional Asymmetry**: Static-to-dynamic translation (45-63% success) significantly outperforms dynamic-to-static (< 10%)
2. **Model Specialization**: Different LLMs show advantages for specific translation pairs
3. **Complexity Impact**: Repository complexity inversely correlates with translation success

## ðŸ”¬ Research Applications

RepoTransBench enables research in:

- **Code Translation**: Develop and evaluate new translation methods
- **LLM Capabilities**: Assess model performance on complex, real-world tasks
- **Software Engineering**: Study repository-level code migration challenges
- **Multi-Agent Systems**: Design collaborative AI systems for complex tasks

## ðŸ“ Project Structure

```
RepoTransBench/
â”œâ”€â”€ RepoTransAgent/              # ðŸ¤– Main agent framework
â”‚   â”œâ”€â”€ actions.py              # Action definitions (CreateFile, ReadFile, etc.)
â”‚   â”œâ”€â”€ generator.py            # LLM API client and response handling
â”‚   â”œâ”€â”€ run.py                  # Single project translation script
â”‚   â”œâ”€â”€ run_batch.py            # Batch processing script
â”‚   â”œâ”€â”€ test_analyzer.py        # Multi-language test result analysis
â”‚   â”œâ”€â”€ API_KEY.txt             # API keys configuration
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ system_prompt.py    # System prompt generation
â”œâ”€â”€ multi_agent_based_benchmark_construction/  # ðŸ—ï¸ Benchmark construction tools
â”‚   â”œâ”€â”€ testcase_public_agent_batch/    # Public test generation
â”‚   â”œâ”€â”€ testcase_target_agent_batch/    # Target test translation
â”‚   â”œâ”€â”€ coverage_agent_batch/           # Coverage analysis
â”‚   â””â”€â”€ runnable_agent_batch/           # Environment setup
â”œâ”€â”€ rule_based_filter_scripts/   # ðŸ“‹ Repository filtering tools
â”œâ”€â”€ download_repos_scripts/      # ðŸ“¥ Data collection utilities
â”œâ”€â”€ docker/                      # ðŸ³ Containerization setup
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ assets/                      # ðŸ“Š Paper figures and resources
```

## ðŸ“Š Expected Directory Structure (After Dataset Download)

After downloading the dataset, your `/workspace` directory should look like:

```
/workspace/
â”œâ”€â”€ source_projects/             # Original source code repositories
â”‚   â”œâ”€â”€ Python/
â”‚   â”œâ”€â”€ Java/
â”‚   â”œâ”€â”€ C++/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ target_projects/             # Target translation projects with tests
â”‚   â”œâ”€â”€ projects_summary.jsonl  # Project metadata
â”‚   â”œâ”€â”€ Python/
â”‚   â”‚   â”œâ”€â”€ Java/
â”‚   â”‚   â”‚   â”œâ”€â”€ project1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ run_tests.sh
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ public_tests/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ original_tests/
â”‚   â”‚   â”‚   â””â”€â”€ project2/
â”‚   â”‚   â””â”€â”€ C++/
â”‚   â””â”€â”€ Java/
â”‚       â””â”€â”€ Python/
â””â”€â”€ translated_projects/         # Generated translations (created during execution)
    â””â”€â”€ claude-sonnet-4-20250514/
        â”œâ”€â”€ Python/
        â”‚   â””â”€â”€ Java/
        â””â”€â”€ Java/
            â””â”€â”€ Python/
```

## ðŸ† Leaderboard

We welcome submissions to our leaderboard! Submit your results via GitHub Issues.

| Rank | Method | Model | Success Rate | Paper/Code |
|------|--------|--------|-------------|------------|
| 1 | RepoTransAgent | Claude-4 | 32.8% | [This work] |
| 2 | RepoTransAgent | GPT-4.1 | 32.8% | [This work] |
| 3 | RepoTransAgent | DeepSeek | 22.5% | [This work] |

## ðŸ“„ Citation

If you use RepoTransBench in your research, please cite our paper:

```bibtex
@article{repotransbench2024,
  title={RepoTransBench: A Real-World Multilingual Benchmark for Repository-Level Code Translation},
  author={Wang, Yanli and Wang, Yanlin and Wang, Suiquan and Guo, Daya and Chen, Jiachi and Grundy, John and Liu, Xilin and Ma, Yuchi and Mao, Mingzhi and Zhang, Hongyu and Zheng, Zibin},
  journal={arXiv preprint arXiv:2024.xxxxx},
  year={2024}
}
```

## ðŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Ways to Contribute

- ðŸ› Report bugs and issues
- ðŸ’¡ Suggest new features or translation pairs
- ðŸ“ Improve documentation
- ðŸ§ª Add new evaluation methods
- ðŸ”„ Submit translation results

## ðŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Thanks to all contributors who helped build this benchmark
- Special thanks to the open-source community for providing repositories
- Supported by Sun Yat-sen University, Monash University, Huawei Cloud, and Chongqing University

## ðŸ“ž Contact

For questions or collaboration opportunities:

- **Primary Contact**: Yanlin Wang (wangylin36@mail.sysu.edu.cn)
- **Issues**: Please use [GitHub Issues](https://github.com/DeepSoftwareAnalytics/RepoTransBench/issues)
- **Discussions**: Join our [GitHub Discussions](https://github.com/DeepSoftwareAnalytics/RepoTransBench/discussions)

---

â­ **Star this repository if you find it useful!** â­