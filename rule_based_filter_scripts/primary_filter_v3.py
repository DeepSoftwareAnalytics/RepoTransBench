#!/usr/bin/env python3
"""
é«˜æ€§èƒ½é¡¹ç›®è¿‡æ»¤è„šæœ¬ - ä¿®å¤å¡ä½å’Œå¤šè¿›ç¨‹é—®é¢˜
ä¸»è¦ä¿®å¤ï¼š
1. æ·»åŠ è¶…æ—¶æœºåˆ¶é˜²æ­¢å¡ä½
2. æ”¹è¿›é”™è¯¯å¤„ç†å’Œè¿›ç¨‹ç®¡ç†
3. ä¿®å¤å¤åˆ¶æ“ä½œçš„å„ç§è¾¹ç•Œæƒ…å†µ
4. ç¡®ä¿å¤šè¿›ç¨‹æ­£ç¡®ç»“æŸ
"""

import os
import shutil
import re
import signal
import threading
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
import json
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed, TimeoutError
import time
from collections import defaultdict
import mmap
from functools import lru_cache
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TimeoutError(Exception):
    """è‡ªå®šä¹‰è¶…æ—¶å¼‚å¸¸"""
    pass

def timeout_handler(signum, frame):
    """è¶…æ—¶ä¿¡å·å¤„ç†å™¨"""
    raise TimeoutError("Operation timed out")

def safe_rmtree(path: Path, max_retries: int = 3) -> bool:
    """å®‰å…¨åˆ é™¤ç›®å½•æ ‘ï¼Œå¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ"""
    for attempt in range(max_retries):
        try:
            if path.exists():
                # å¤„ç†åªè¯»æ–‡ä»¶
                def handle_remove_readonly(func, path, exc):
                    if os.path.exists(path):
                        os.chmod(path, 0o777)
                        func(path)
                
                shutil.rmtree(path, onerror=handle_remove_readonly)
            return True
        except (PermissionError, OSError) as e:
            if attempt == max_retries - 1:
                logger.warning(f"æ— æ³•åˆ é™¤ç›®å½• {path}: {e}")
                return False
            time.sleep(0.1 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
    return False

def safe_copytree(src: Path, dst: Path, timeout: int = 60) -> bool:
    """å®‰å…¨å¤åˆ¶ç›®å½•æ ‘ï¼Œå¸¦è¶…æ—¶å’Œé”™è¯¯å¤„ç†"""
    def copy_with_timeout():
        try:
            # è‡ªå®šä¹‰å¿½ç•¥å‡½æ•°ï¼Œè·³è¿‡é—®é¢˜æ–‡ä»¶
            def ignore_problematic_files(directory, contents):
                ignored = []
                for item in contents:
                    item_path = Path(directory) / item
                    try:
                        # è·³è¿‡ç¬¦å·é“¾æ¥
                        if item_path.is_symlink():
                            ignored.append(item)
                            continue
                        # è·³è¿‡è¿‡å¤§çš„æ–‡ä»¶ (>100MB)
                        if item_path.is_file() and item_path.stat().st_size > 100 * 1024 * 1024:
                            ignored.append(item)
                            continue
                        # è·³è¿‡ç‰¹æ®Šæ–‡ä»¶ç±»å‹
                        if item.startswith('.') and item in {'.git', '.svn', '.hg', '__pycache__'}:
                            ignored.append(item)
                            continue
                    except (OSError, PermissionError):
                        ignored.append(item)
                        continue
                return ignored
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•ä¸å­˜åœ¨
            if dst.exists():
                safe_rmtree(dst)
            
            # å¤åˆ¶ç›®å½•
            shutil.copytree(
                src, dst, 
                ignore=ignore_problematic_files,
                dirs_exist_ok=False,
                ignore_dangling_symlinks=True,
                symlinks=False  # ä¸å¤åˆ¶ç¬¦å·é“¾æ¥
            )
            return True
            
        except Exception as e:
            logger.error(f"å¤åˆ¶å¤±è´¥ {src} -> {dst}: {e}")
            return False
    
    # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶æœºåˆ¶
    result = [False]
    
    def worker():
        result[0] = copy_with_timeout()
    
    thread = threading.Thread(target=worker)
    thread.daemon = True
    thread.start()
    thread.join(timeout)
    
    if thread.is_alive():
        logger.warning(f"å¤åˆ¶è¶…æ—¶ {src} -> {dst}")
        return False
    
    return result[0]

class FastProjectFilter:
    def __init__(self, source_dir: str, target_dir: str, max_workers: int = None):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        # å‡å°‘å·¥ä½œè¿›ç¨‹æ•°ï¼Œé¿å…èµ„æºç«äº‰
        self.max_workers = max_workers or min(mp.cpu_count(), 4)
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        self.target_dir.mkdir(exist_ok=True)
        
        # ä¼˜åŒ–çš„è¿‡æ»¤è§„åˆ™ - åŒ…å«æ‰€æœ‰éœ€è¦çš„è¯­è¨€
        self.filter_rules = {
            'Python': {
                'extensions': {'.py'},
                'exclude_patterns': [
                    # æ·±åº¦å­¦ä¹ /æœºå™¨å­¦ä¹ æ¡†æ¶
                    rb'\b(?:import\s+(?:torch|tensorflow|keras|sklearn|numpy|pandas|scipy|opencv|cv2|PIL|Pillow)|from\s+(?:torch|tensorflow|keras|sklearn|numpy|pandas|scipy|opencv|cv2|PIL|Pillow))\b',
                    # GUIæ¡†æ¶
                    rb'\b(?:import\s+(?:tkinter|PyQt[56]|PySide[26]|kivy)|from\s+(?:tkinter|PyQt[56]|PySide[26]|kivy))\b',
                    # å¹³å°ç‰¹å®š
                    rb'\b(?:import\s+(?:win32api|win32gui|pywin32)|from\s+(?:win32api|win32gui|pywin32))\b',
                    # æ¸¸æˆå¼•æ“
                    rb'\b(?:import\s+(?:pygame|panda3d)|from\s+(?:pygame|panda3d))\b',
                ],
                'test_files': {
                    'test_*.py', '*_test.py', 'conftest.py', 'pytest.ini', 'tox.ini', 'setup.cfg'
                },
                'test_dirs': {'test', 'tests'}
            },
            'C++': {
                'extensions': {'.cpp', '.cc', '.cxx', '.c++', '.h', '.hpp', '.hxx', '.h++'},
                'exclude_patterns': [
                    # GUIæ¡†æ¶
                    rb'#include\s*[<"](?:Qt/|gtk/|wxWidgets|FLTK)',
                    # æ¸¸æˆå¼•æ“
                    rb'#include\s*[<"](?:unreal|unity|ogre)',
                    # å›¾å½¢API
                    rb'#include\s*[<"](?:OpenGL|DirectX|Vulkan)',
                    # å¹³å°ç‰¹å®š
                    rb'#include\s*[<"](?:windows\.h|win32)',
                    # è®¡ç®—æœºè§†è§‰
                    rb'#include\s*[<"](?:opencv)',
                ],
                'test_files': {'test_*.cpp', '*_test.cpp', 'test_*.cc', '*_test.cc', 'CMakeLists.txt', 'Makefile'},
                'test_dirs': {'test', 'tests'}
            },
            'JavaScript': {
                'extensions': {'.js', '.jsx', '.ts', '.tsx', '.mjs'},
                'exclude_patterns': [
                    # å‰ç«¯æ¡†æ¶
                    rb'\b(?:import\s+.*(?:react|vue|angular|svelte)|require\s*\(\s*["\'].*(?:react|vue|angular|svelte)|from\s+["\'].*(?:react|vue|angular|svelte))\b',
                    # æ„å»ºå·¥å…·
                    rb'\b(?:import\s+.*(?:webpack|vite|rollup|parcel)|require\s*\(\s*["\'].*(?:webpack|vite|rollup|parcel))\b',
                    # æµè§ˆå™¨ç‰¹å®š
                    rb'\b(?:document\.|window\.|jquery|\$\()',
                    # Node.jsç‰¹å®š
                    rb'\b(?:import\s+.*electron|require\s*\(\s*["\'].*electron)\b',
                ],
                'test_files': {
                    '*.test.js', '*.test.ts', '*.spec.js', '*.spec.ts',
                    'jest.config.*', 'mocha.opts', 'karma.conf.*', 'package.json'
                },
                'test_dirs': {'test', 'tests', '__tests__', 'spec'}
            },
            'C': {
                'extensions': {'.c', '.h'},
                'exclude_patterns': [
                    # å¹³å°ç‰¹å®šå¤´æ–‡ä»¶
                    rb'#include\s*[<"](?:windows\.h|win32)',
                    # GUI
                    rb'#include\s*[<"](?:gtk/|qt)',
                    # ç³»ç»Ÿè°ƒç”¨
                    rb'#include\s*[<"](?:sys/|unistd\.h)',
                ],
                'test_files': {'test_*.c', '*_test.c', 'Makefile', 'CMakeLists.txt'},
                'test_dirs': {'test', 'tests'}
            },
            'Java': {
                'extensions': {'.java'},
                'exclude_patterns': [
                    # Androidå¼€å‘
                    rb'\bimport\s+(?:android|androidx\.)',
                    # GUIæ¡†æ¶
                    rb'\bimport\s+(?:javax\.swing|java\.awt|javafx)',
                    # æ¸¸æˆå¼•æ“
                    rb'\bimport\s+(?:lwjgl|libgdx)',
                ],
                'test_files': {'*Test.java', '*Tests.java', 'pom.xml', 'build.gradle', 'build.xml'},
                'test_dirs': {'test', 'src/test'}
            },
            'Matlab': {
                'extensions': {'.m'},
                'exclude_patterns': [
                    # Matlabç‰¹å®šå·¥å…·ç®±
                    rb'\b(?:Simulink|toolbox)',
                    # å›¾å½¢ç›¸å…³
                    rb'\b(?:plot|figure|imshow|imagesc|surf|mesh)\s*\(',
                    # ä¿¡å·å¤„ç†å·¥å…·ç®±
                    rb'\b(?:fft|ifft|filter|freqz)\s*\(',
                ],
                'test_files': {'test*.m', '*_test.m', 'runtests.m'},
                'test_dirs': {'test', 'tests'}
            },
            'C#': {
                'extensions': {'.cs'},
                'exclude_patterns': [
                    # å¹³å°ç‰¹å®š
                    rb'\busing\s+(?:System\.Windows|Microsoft\.Win32)',
                    # GUIæ¡†æ¶
                    rb'\busing\s+(?:System\.Windows\.Forms|System\.Windows\.Controls)',
                    # æ¸¸æˆå¼•æ“
                    rb'\busing\s+(?:UnityEngine|Microsoft\.Xna)',
                    # ASP.NET
                    rb'\busing\s+(?:System\.Web)',
                ],
                'test_files': {'*Test.cs', '*Tests.cs', '*.csproj', '*.sln'},
                'test_dirs': {'test', 'Test', 'Tests'}
            }
        }
        
        # é¢„ç¼–è¯‘æ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼
        self._precompile_patterns()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'files_checked': 0,
            'pattern_matches': 0,
            'projects_analyzed': 0
        }
    
    def _precompile_patterns(self):
        """é¢„ç¼–è¯‘æ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        self.compiled_patterns = {}
        
        for language, rules in self.filter_rules.items():
            compiled_rules = {
                'extensions': rules['extensions'],
                'exclude_patterns': [],
                'test_files': rules['test_files'],
                'test_dirs': rules['test_dirs']
            }
            
            # ç¼–è¯‘æ’é™¤æ¨¡å¼
            for pattern in rules['exclude_patterns']:
                try:
                    compiled_rules['exclude_patterns'].append(
                        re.compile(pattern, re.MULTILINE | re.IGNORECASE)
                    )
                except re.error as e:
                    logger.warning(f"Failed to compile pattern {pattern}: {e}")
            
            self.compiled_patterns[language] = compiled_rules
    
    @staticmethod
    def fast_file_check(file_path: Path, patterns: List[re.Pattern], max_size: int = 512 * 1024) -> bool:
        """é«˜æ•ˆçš„æ–‡ä»¶å†…å®¹æ£€æŸ¥ - å¸¦è¶…æ—¶ä¿æŠ¤"""
        try:
            # è·³è¿‡è¿‡å¤§çš„æ–‡ä»¶
            file_size = file_path.stat().st_size
            if file_size > max_size:
                return False
            
            if file_size == 0:
                return False
            
            # è®¾ç½®è¶…æ—¶ä¿æŠ¤
            def read_file_content():
                with open(file_path, 'rb') as f:
                    if file_size < 8192:
                        return f.read()
                    else:
                        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                            return mm[:]
            
            # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶
            content = None
            result = [None]
            
            def worker():
                try:
                    result[0] = read_file_content()
                except Exception as e:
                    result[0] = None
            
            thread = threading.Thread(target=worker)
            thread.daemon = True
            thread.start()
            thread.join(timeout=5)  # 5ç§’è¶…æ—¶
            
            if thread.is_alive() or result[0] is None:
                return False
            
            content = result[0]
            
            # æ£€æŸ¥æ¨¡å¼åŒ¹é…
            for pattern in patterns:
                if pattern.search(content):
                    return True
                    
            return False
            
        except (OSError, PermissionError, UnicodeDecodeError):
            return False
    
    @staticmethod
    def quick_test_check(project_path: Path, test_files: Set[str], test_dirs: Set[str]) -> bool:
        """å¿«é€Ÿæ£€æŸ¥æµ‹è¯•æ–‡ä»¶ - å¸¦è¶…æ—¶ä¿æŠ¤"""
        try:
            # é¦–å…ˆæ£€æŸ¥å¸¸è§çš„æµ‹è¯•ç›®å½•
            for test_dir in test_dirs:
                test_path = project_path / test_dir
                if test_path.exists() and test_path.is_dir():
                    try:
                        if any(test_path.iterdir()):
                            return True
                    except (PermissionError, OSError):
                        continue
            
            # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ¨¡å¼ - é™åˆ¶æœç´¢èŒƒå›´
            files_checked = 0
            max_files = 30
            max_depth = 2
            
            def check_directory(dir_path: Path, depth: int) -> bool:
                nonlocal files_checked
                if depth > max_depth or files_checked > max_files:
                    return False
                    
                try:
                    for item in dir_path.iterdir():
                        if files_checked > max_files:
                            return False
                            
                        if item.is_file():
                            files_checked += 1
                            for pattern in test_files:
                                if item.match(pattern):
                                    return True
                        elif item.is_dir() and not item.name.startswith('.'):
                            if check_directory(item, depth + 1):
                                return True
                except (PermissionError, OSError):
                    pass
                return False
            
            return check_directory(project_path, 0)
        except Exception:
            return False
    
    @staticmethod
    def analyze_project_with_timeout(args: tuple) -> tuple:
        """å¸¦è¶…æ—¶çš„é¡¹ç›®åˆ†æ"""
        project_path_str, language, compiled_rules = args
        
        # è®¾ç½®è¿›ç¨‹è¶…æ—¶
        def timeout_handler(signum, frame):
            raise TimeoutError("Analysis timeout")
        
        # åªåœ¨Unixç³»ç»Ÿä¸Šè®¾ç½®ä¿¡å·å¤„ç†å™¨
        if hasattr(signal, 'SIGALRM'):
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(30)  # 30ç§’è¶…æ—¶
        
        try:
            result = FastProjectFilter.analyze_project_fast((project_path_str, language, compiled_rules))
            return result
        except TimeoutError:
            return project_path_str, True, ["Analysis timeout"], 0, 0
        except Exception as e:
            return project_path_str, True, [f"Analysis error: {str(e)}"], 0, 0
        finally:
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
    
    @staticmethod
    def analyze_project_fast(args: tuple) -> tuple:
        """å¿«é€Ÿåˆ†æå•ä¸ªé¡¹ç›®"""
        project_path_str, language, compiled_rules = args
        project_path = Path(project_path_str)
        
        try:
            # 1. å¿«é€Ÿæµ‹è¯•æ£€æŸ¥
            if not FastProjectFilter.quick_test_check(
                project_path, 
                compiled_rules['test_files'], 
                compiled_rules['test_dirs']
            ):
                return project_path_str, True, ["No tests found"], 0, 0
            
            # 2. å¿«é€Ÿä»£ç æ–‡ä»¶æ£€æŸ¥
            excluded_count = 0
            total_count = 0
            max_files = 15  # è¿›ä¸€æ­¥å‡å°‘æ£€æŸ¥æ–‡ä»¶æ•°
            
            patterns = compiled_rules['exclude_patterns']
            extensions = compiled_rules['extensions']
            
            # åªæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•å’Œä¸€çº§å­ç›®å½•
            dirs_to_check = [project_path]
            try:
                for item in project_path.iterdir():
                    if item.is_dir() and not item.name.startswith('.') and len(dirs_to_check) < 3:
                        dirs_to_check.append(item)
            except (PermissionError, OSError):
                pass
            
            for dir_path in dirs_to_check:
                if total_count >= max_files:
                    break
                    
                try:
                    for file_path in dir_path.iterdir():
                        if total_count >= max_files:
                            break
                            
                        if file_path.is_file() and file_path.suffix in extensions:
                            total_count += 1
                            if FastProjectFilter.fast_file_check(file_path, patterns):
                                excluded_count += 1
                                if excluded_count > max_files * 0.6:
                                    break
                except (PermissionError, OSError):
                    continue
            
            # 3. å†³ç­–é€»è¾‘
            should_exclude = False
            reasons = []
            
            if total_count > 0:
                exclusion_ratio = excluded_count / total_count
                if exclusion_ratio > 0.5:
                    should_exclude = True
                    reasons.append(f"Too many files use untranslatable libraries: {excluded_count}/{total_count} ({exclusion_ratio:.1%})")
            
            return project_path_str, should_exclude, reasons, total_count, excluded_count
            
        except Exception as e:
            return project_path_str, True, [f"Analysis error: {str(e)}"], 0, 0
    
    def get_projects_batch(self) -> List[Tuple[str, str]]:
        """æ‰¹é‡è·å–é¡¹ç›®åˆ—è¡¨"""
        projects = []
        
        for language in self.compiled_patterns.keys():
            language_dir = self.source_dir / language
            if not language_dir.exists():
                continue
                
            try:
                for project_dir in language_dir.iterdir():
                    if project_dir.is_dir():
                        projects.append((str(project_dir), language))
            except (PermissionError, OSError):
                logger.warning(f"Permission denied: {language_dir}")
                continue
        
        return projects
    
    def copy_project_safe(self, source_path: str, target_path: str) -> bool:
        """å®‰å…¨å¤åˆ¶é¡¹ç›®"""
        try:
            source = Path(source_path)
            target = Path(target_path)
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            target.parent.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨æ”¹è¿›çš„å¤åˆ¶å‡½æ•°
            return safe_copytree(source, target, timeout=60)
                
        except Exception as e:
            logger.error(f"å¤åˆ¶å¤±è´¥ {source_path}: {e}")
            return False
    
    def filter_projects(self):
        """æ‰§è¡Œé«˜æ€§èƒ½é¡¹ç›®è¿‡æ»¤"""
        logger.info(f"ğŸš€ å¯åŠ¨é«˜æ€§èƒ½è¿‡æ»¤å™¨ï¼Œä½¿ç”¨ {self.max_workers} ä¸ªå·¥ä½œè¿›ç¨‹")
        
        start_time = time.time()
        
        # æ‰¹é‡è·å–æ‰€æœ‰é¡¹ç›®
        all_projects = self.get_projects_batch()
        total_projects = len(all_projects)
        logger.info(f"å‘ç° {total_projects} ä¸ªé¡¹ç›®")
        
        if total_projects == 0:
            logger.warning("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®")
            return {}
        
        # å‡†å¤‡æ‰¹å¤„ç†å‚æ•°
        process_args = [
            (project_path, language, self.compiled_patterns[language])
            for project_path, language in all_projects
        ]
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = defaultdict(lambda: {'total': 0, 'kept': 0, 'excluded': 0})
        projects_to_copy = []
        processed = 0
        
        logger.info("å¼€å§‹åˆ†æé¡¹ç›®...")
        
        # ä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡ï¼Œæ›´å¥½çš„é”™è¯¯å¤„ç†
        batch_size = 50
        
        for i in range(0, len(process_args), batch_size):
            batch = process_args[i:i + batch_size]
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿è¿›ç¨‹æ± æ­£ç¡®å…³é—­
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_args = {
                    executor.submit(self.analyze_project_with_timeout, args): args 
                    for args in batch
                }
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡ï¼Œè®¾ç½®è¶…æ—¶
                try:
                    for future in as_completed(future_to_args, timeout=120):  # 2åˆ†é’Ÿæ‰¹æ¬¡è¶…æ—¶
                        try:
                            project_path, should_exclude, reasons, total_files, excluded_files = future.result(timeout=60)
                            
                            language = Path(project_path).parent.name
                            project_name = Path(project_path).name
                            
                            stats[language]['total'] += 1
                            processed += 1
                            
                            if should_exclude:
                                stats[language]['excluded'] += 1
                            else:
                                stats[language]['kept'] += 1
                                projects_to_copy.append((project_path, language, project_name))
                            
                            # å®šæœŸè¾“å‡ºè¿›åº¦
                            if processed % 20 == 0:
                                elapsed = time.time() - start_time
                                rate = processed / elapsed if elapsed > 0 else 0
                                eta = (total_projects - processed) / rate if rate > 0 else 0
                                logger.info(f"åˆ†æè¿›åº¦: {processed}/{total_projects} ({processed/total_projects*100:.1f}%) "
                                          f"é€Ÿåº¦: {rate:.1f}/ç§’ é¢„è®¡å‰©ä½™: {eta:.0f}ç§’")
                        
                        except TimeoutError:
                            logger.warning("ä»»åŠ¡è¶…æ—¶ï¼Œè·³è¿‡")
                            processed += 1
                        except Exception as e:
                            logger.error(f"å¤„ç†ä»»åŠ¡æ—¶å‡ºé”™: {e}")
                            processed += 1
                
                except TimeoutError:
                    logger.warning("æ‰¹æ¬¡å¤„ç†è¶…æ—¶ï¼Œç»§ç»­ä¸‹ä¸€æ‰¹")
                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                    for future in future_to_args:
                        future.cancel()
        
        analysis_time = time.time() - start_time
        logger.info(f"âœ… åˆ†æå®Œæˆï¼è€—æ—¶: {analysis_time:.1f}ç§’")
        logger.info(f"éœ€è¦å¤åˆ¶ {len(projects_to_copy)} ä¸ªé¡¹ç›®")
        
        # ä¸²è¡Œå¤åˆ¶ï¼Œé¿å…å¹¶å‘é—®é¢˜
        if projects_to_copy:
            logger.info("å¼€å§‹å¤åˆ¶é¡¹ç›®...")
            copy_start = time.time()
            
            copied_count = 0
            failed_count = 0
            
            for i, (project_path, language, project_name) in enumerate(projects_to_copy):
                try:
                    target_lang_dir = self.target_dir / language
                    target_lang_dir.mkdir(exist_ok=True)
                    target_project_path = str(target_lang_dir / project_name)
                    
                    if self.copy_project_safe(project_path, target_project_path):
                        copied_count += 1
                    else:
                        failed_count += 1
                        
                    if (i + 1) % 10 == 0:
                        logger.info(f"å¤åˆ¶è¿›åº¦: {i + 1}/{len(projects_to_copy)} (æˆåŠŸ: {copied_count}, å¤±è´¥: {failed_count})")
                        
                except Exception as e:
                    logger.error(f"å¤åˆ¶é¡¹ç›®æ—¶å‡ºé”™: {e}")
                    failed_count += 1
            
            copy_time = time.time() - copy_start
            logger.info(f"âœ… å¤åˆ¶å®Œæˆï¼è€—æ—¶: {copy_time:.1f}ç§’ï¼ŒæˆåŠŸ: {copied_count}ï¼Œå¤±è´¥: {failed_count}")
        
        # ä¿å­˜ç»Ÿè®¡
        stats_dict = dict(stats)
        stats_file = self.target_dir / 'filter_stats.json'
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats_dict, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")
        
        total_time = time.time() - start_time
        logger.info(f"\nğŸ‰ è¿‡æ»¤å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")
        logger.info(f"å¹³å‡å¤„ç†é€Ÿåº¦: {total_projects/total_time:.1f} é¡¹ç›®/ç§’")
        
        return stats_dict

def main():
    source_dir = "github_repos"
    target_dir = "primary_filter_v3"
    
    if not os.path.exists(source_dir):
        logger.error(f"âŒ æºç›®å½• {source_dir} ä¸å­˜åœ¨")
        return
    
    # ä½¿ç”¨ä¿å®ˆçš„å·¥ä½œè¿›ç¨‹æ•°
    max_workers = min(mp.cpu_count(), 4)
    logger.info(f"ğŸ–¥ï¸  æ£€æµ‹åˆ° {mp.cpu_count()} ä¸ªCPUæ ¸å¿ƒï¼Œä½¿ç”¨ {max_workers} ä¸ªè¿›ç¨‹")
    
    try:
        filter_instance = FastProjectFilter(source_dir, target_dir, max_workers)
        stats = filter_instance.filter_projects()
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print("-" * 60)
        if stats:
            total_projects = sum(s['total'] for s in stats.values())
            kept_projects = sum(s['kept'] for s in stats.values())
            excluded_projects = sum(s['excluded'] for s in stats.values())
            
            print(f"ğŸ“ˆ æ€»é¡¹ç›®æ•°: {total_projects:,}")
            print(f"âœ… ä¿ç•™é¡¹ç›®: {kept_projects:,}")
            print(f"âŒ æ’é™¤é¡¹ç›®: {excluded_projects:,}")
            if total_projects > 0:
                print(f"ğŸ“‹ ä¿ç•™ç‡: {kept_projects/total_projects*100:.1f}%")
            
            print(f"\nğŸ” å„è¯­è¨€è¯¦æƒ…:")
            for lang, stat in sorted(stats.items()):
                if stat['total'] > 0:
                    keep_rate = stat['kept'] / stat['total'] * 100
                    print(f"  {lang:>12}: {stat['kept']:>4}/{stat['total']:>4} ({keep_rate:>5.1f}%)")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®")
    
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        logger.info("\nğŸ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main()