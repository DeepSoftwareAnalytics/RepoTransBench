#!/usr/bin/env python3
# file path: batch_run.py

import json
import os
import subprocess
import sys
from pathlib import Path
from collections import defaultdict
from datetime import datetime
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import threading

def read_projects_summary(file_path):
    """è¯»å–projects_summary.jsonlæ–‡ä»¶"""
    projects = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    project = json.loads(line.strip())
                    projects.append(project)
        print(f"ğŸ“‹ Loaded {len(projects)} projects from {file_path}")
        return projects
    except Exception as e:
        print(f"âŒ Failed to read {file_path}: {e}")
        return []

def group_by_translation_pairs(projects):
    """æŒ‰ç¿»è¯‘å¯¹ï¼ˆæºè¯­è¨€â†’ç›®æ ‡è¯­è¨€ï¼‰åˆ†ç»„é¡¹ç›®"""
    translation_pairs = defaultdict(list)
    
    for project in projects:
        source_lang = project.get('source_language', '')
        target_lang = project.get('target_language', '')
        
        if source_lang and target_lang:
            pair_key = f"{source_lang}â†’{target_lang}"
            translation_pairs[pair_key].append(project)
    
    return translation_pairs

def select_projects_to_run(translation_pairs, max_per_pair=5):
    """ä¸ºæ¯ä¸ªç¿»è¯‘å¯¹é€‰æ‹©å‰Nä¸ªé¡¹ç›®"""
    selected_projects = []
    
    for pair_key, projects in translation_pairs.items():
        # æŒ‰é¡¹ç›®åç§°æ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
        sorted_projects = sorted(projects, key=lambda x: x.get('project_name', ''))
        
        # é€‰æ‹©å‰max_per_pairä¸ªé¡¹ç›®
        selected = sorted_projects[:max_per_pair]
        selected_projects.extend(selected)
        
        print(f"ğŸ“¦ {pair_key}: Selected {len(selected)} out of {len(projects)} projects")
        for project in selected:
            print(f"   - {project.get('project_name', 'Unknown')}")
    
    return selected_projects

def run_single_translation(args):
    """è¿è¡Œå•ä¸ªç¿»è¯‘ä»»åŠ¡ - ç”¨äºå¤šè¿›ç¨‹"""
    project, base_dir, max_iterations, process_id = args
    
    project_name = project.get('project_name', '')
    source_language = project.get('source_language', '')
    target_language = project.get('target_language', '')
    
    print(f"ğŸš€ [P{process_id:02d}] Starting: {project_name} ({source_language} â†’ {target_language})")
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        'python', '-m', 'RepoTransAgent.run',
        '--project_name', project_name,
        '--source_language', source_language,
        '--target_language', target_language,
        '--max_iterations', str(max_iterations)
    ]
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd,
            cwd=base_dir,
            capture_output=True,
            text=True,
            timeout=1800  # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        
        # åˆ¤æ–­ç»“æœ
        if result.returncode == 0:
            status = "âœ… SUCCESS"
        elif result.returncode == 1:
            status = "âŒ FAILED"
        elif result.returncode == 2:
            status = "â±ï¸ TIMEOUT"
        elif result.returncode == 3:
            status = "ğŸ›‘ INTERRUPTED"
        else:
            status = f"âŒ ERROR (code: {result.returncode})"
        
        print(f"[P{process_id:02d}] {status} - {project_name} - {execution_time:.1f}s")
        
        return {
            'project_name': project_name,
            'source_language': source_language,
            'target_language': target_language,
            'status': status,
            'return_code': result.returncode,
            'execution_time': execution_time,
            'process_id': process_id,
            'stdout': result.stdout[-2000:],  # åªä¿ç•™æœ€å2000å­—ç¬¦
            'stderr': result.stderr[-2000:]   # åªä¿ç•™æœ€å2000å­—ç¬¦
        }
        
    except subprocess.TimeoutExpired:
        execution_time = time.time() - start_time
        print(f"[P{process_id:02d}] â±ï¸ TIMEOUT - {project_name} - {execution_time:.1f}s")
        
        return {
            'project_name': project_name,
            'source_language': source_language,
            'target_language': target_language,
            'status': "â±ï¸ TIMEOUT",
            'return_code': -1,
            'execution_time': execution_time,
            'process_id': process_id,
            'stdout': '',
            'stderr': 'Process timed out after 30 minutes'
        }
        
    except Exception as e:
        execution_time = time.time() - start_time
        print(f"[P{process_id:02d}] ğŸ’¥ EXCEPTION - {project_name} - {str(e)}")
        
        return {
            'project_name': project_name,
            'source_language': source_language,
            'target_language': target_language,
            'status': f"ğŸ’¥ EXCEPTION: {str(e)}",
            'return_code': -2,
            'execution_time': execution_time,
            'process_id': process_id,
            'stdout': '',
            'stderr': str(e)
        }

class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    def __init__(self, total_tasks):
        self.total_tasks = total_tasks
        self.completed_tasks = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
        self.results = []
    
    def update(self, result):
        with self.lock:
            self.completed_tasks += 1
            self.results.append(result)
            
            elapsed = time.time() - self.start_time
            if self.completed_tasks > 0:
                avg_time = elapsed / self.completed_tasks
                estimated_remaining = (self.total_tasks - self.completed_tasks) * avg_time
                
                success_count = len([r for r in self.results if r['return_code'] == 0])
                
                print(f"ğŸ“Š Progress: {self.completed_tasks}/{self.total_tasks} "
                      f"({self.completed_tasks/self.total_tasks*100:.1f}%) - "
                      f"Success: {success_count}/{self.completed_tasks} - "
                      f"ETA: {estimated_remaining/60:.1f}min")

def run_parallel_translations(selected_projects, base_dir, max_iterations, num_processes=20):
    """å¹¶è¡Œè¿è¡Œç¿»è¯‘ä»»åŠ¡"""
    print(f"\nğŸš€ Starting parallel translation with {num_processes} processes...")
    print(f"   Total projects: {len(selected_projects)}")
    print(f"   Max iterations per project: {max_iterations}")
    print(f"   Timeout per project: 30 minutes")
    
    # å‡†å¤‡å‚æ•°
    task_args = []
    for i, project in enumerate(selected_projects):
        task_args.append((project, base_dir, max_iterations, i + 1))
    
    # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ªå™¨
    tracker = ProgressTracker(len(selected_projects))
    
    # å¼€å§‹å¹¶è¡Œæ‰§è¡Œ
    results = []
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=num_processes) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_args = {executor.submit(run_single_translation, args): args for args in task_args}
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_args):
            try:
                result = future.result()
                results.append(result)
                tracker.update(result)
                
            except Exception as e:
                args = future_to_args[future]
                project = args[0]
                process_id = args[3]
                
                error_result = {
                    'project_name': project.get('project_name', ''),
                    'source_language': project.get('source_language', ''),
                    'target_language': project.get('target_language', ''),
                    'status': f"ğŸ’¥ EXECUTOR ERROR: {str(e)}",
                    'return_code': -3,
                    'execution_time': 0,
                    'process_id': process_id,
                    'stdout': '',
                    'stderr': str(e)
                }
                results.append(error_result)
                tracker.update(error_result)
                
                print(f"[P{process_id:02d}] ğŸ’¥ EXECUTOR ERROR: {e}")
    
    total_time = time.time() - start_time
    print(f"\nğŸ Parallel execution completed in {total_time/60:.1f} minutes")
    
    return results

def save_results(results, output_file):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSON
    json_file = f"batch_results_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜ç®€è¦æŠ¥å‘Šåˆ°æ–‡æœ¬æ–‡ä»¶
    report_file = f"batch_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("PARALLEL BATCH TRANSLATION RESULTS\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Total Projects: {len(results)}\n")
        f.write(f"Timestamp: {timestamp}\n")
        f.write(f"Execution Mode: Parallel (20 processes)\n\n")
        
        # ç»Ÿè®¡
        success_count = len([r for r in results if r['return_code'] == 0])
        failed_count = len([r for r in results if r['return_code'] == 1])
        timeout_count = len([r for r in results if r['return_code'] == 2])
        error_count = len([r for r in results if r['return_code'] not in [0, 1, 2]])
        
        f.write("SUMMARY:\n")
        f.write(f"âœ… Success: {success_count} ({success_count/len(results)*100:.1f}%)\n")
        f.write(f"âŒ Failed: {failed_count} ({failed_count/len(results)*100:.1f}%)\n")
        f.write(f"â±ï¸ Timeout: {timeout_count} ({timeout_count/len(results)*100:.1f}%)\n")
        f.write(f"ğŸ’¥ Error: {error_count} ({error_count/len(results)*100:.1f}%)\n\n")
        
        # æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
        execution_times = [r['execution_time'] for r in results if r['execution_time'] > 0]
        if execution_times:
            f.write("EXECUTION TIME STATS:\n")
            f.write(f"Average: {sum(execution_times)/len(execution_times):.1f}s\n")
            f.write(f"Min: {min(execution_times):.1f}s\n")
            f.write(f"Max: {max(execution_times):.1f}s\n\n")
        
        # æŒ‰ç¿»è¯‘å¯¹åˆ†ç»„ç»Ÿè®¡
        pairs_stats = defaultdict(list)
        for result in results:
            pair_key = f"{result['source_language']}â†’{result['target_language']}"
            pairs_stats[pair_key].append(result)
        
        f.write("BY TRANSLATION PAIR:\n")
        for pair_key, pair_results in pairs_stats.items():
            pair_success = len([r for r in pair_results if r['return_code'] == 0])
            f.write(f"{pair_key}: {pair_success}/{len(pair_results)} success ({pair_success/len(pair_results)*100:.1f}%)\n")
        
        f.write("\nDETAILED RESULTS:\n")
        f.write("-" * 80 + "\n")
        
        # æŒ‰å®Œæˆæ—¶é—´æ’åº
        sorted_results = sorted(results, key=lambda x: x.get('process_id', 0))
        
        for result in sorted_results:
            f.write(f"Project: {result['project_name']} [P{result.get('process_id', 0):02d}]\n")
            f.write(f"Translation: {result['source_language']} â†’ {result['target_language']}\n")
            f.write(f"Status: {result['status']}\n")
            f.write(f"Time: {result['execution_time']:.1f}s\n")
            if result['stderr'] and result['stderr'] != 'Process timed out after 30 minutes':
                f.write(f"Error: {result['stderr'][:200]}...\n")
            f.write("-" * 40 + "\n")
    
    print(f"\nğŸ“Š Results saved to:")
    print(f"   ğŸ“‹ Detailed: {json_file}")
    print(f"   ğŸ“„ Report: {report_file}")

def main():
    print("ğŸ¤– Parallel Batch Translation Runner")
    print("=" * 50)
    
    # é…ç½®
    projects_summary_path = "/workspace/target_projects/projects_summary.jsonl"
    base_dir = "/workspace/methods"
    max_per_pair = 1000
    max_iterations = 20
    num_processes = 50
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(projects_summary_path):
        print(f"âŒ projects_summary.jsonl not found at: {projects_summary_path}")
        sys.exit(1)
    
    if not os.path.exists(base_dir):
        print(f"âŒ Base directory not found: {base_dir}")
        sys.exit(1)
    
    # æ£€æŸ¥CPUæ ¸å¿ƒæ•°
    cpu_count = mp.cpu_count()
    print(f"ğŸ’» System CPU cores: {cpu_count}")
    if num_processes > cpu_count:
        print(f"âš ï¸ Warning: Using {num_processes} processes on {cpu_count} cores")
    
    # è¯»å–é¡¹ç›®
    projects = read_projects_summary(projects_summary_path)
    if not projects:
        print("âŒ No projects found")
        sys.exit(1)
    
    # æŒ‰ç¿»è¯‘å¯¹åˆ†ç»„
    translation_pairs = group_by_translation_pairs(projects)
    print(f"\nğŸ“¦ Found {len(translation_pairs)} translation pairs:")
    for pair_key, projects_list in translation_pairs.items():
        print(f"   {pair_key}: {len(projects_list)} projects")
    
    # é€‰æ‹©è¦è¿è¡Œçš„é¡¹ç›®
    selected_projects = select_projects_to_run(translation_pairs, max_per_pair)
    # import pandas as pd
    # df = pd.DataFrame(selected_projects)
    # selected_projects = df.groupby(['source_language', 'target_language']).head(10).to_dict('records')
    # print(len(selected_projects))
    # exit()
    # æ–­ç‚¹ç»­ä¼ ï¼šè¿‡æ»¤å·²å®Œæˆé¡¹ç›®
    completed = set()
    model_name = "claude-sonnet-4-20250514"
    logs_dir = Path(f"/workspace/methods/logs/{model_name.replace('/', '_')}")
    if logs_dir.exists():
        for log_dir in logs_dir.rglob("*/"):
            if (log_dir / "final_summary.txt").exists():
                # if 'Java_to_Python' not in log_dir.name:
                parts = log_dir.name.split('_')
                completed.add('_'.join(parts[:-2]))
                # with open(log_dir / "final_summary.txt", "r") as f:
                #     final_summary = f.read()
                # if ("Final Status: success" in final_summary):
                #     parts = log_dir.name.split('_')
                #     completed.add('_'.join(parts[:-2]))
    # print(completed)
    selected_projects = [p for p in selected_projects if f"{p['project_name']}_{p['source_language']}_to_{p['target_language']}" not in completed]
    selected_projects = selected_projects[::-1]
    # print(len(selected_projects))
    # exit()
    # selected_projects = [project for project in selected_projects if (project['target_language'] in ["Rust"]) and (project['source_language'] in ["Python"]) and (project['project_name'] in ["ramonhagenaars_jsons", "socialwifi_RouterOS-api"])]
    # print(len(selected_projects))
    # exit()
    print(f"\nğŸ¯ Selected {len(selected_projects)} projects to run")
    
    # ç¡®è®¤è¿è¡Œ
    print(f"\nâš¡ Configuration:")
    print(f"   ğŸ“Š Projects: {len(selected_projects)}")
    print(f"   ğŸ”„ Processes: {num_processes}")
    print(f"   ğŸ” Max iterations per project: {max_iterations}")
    print(f"   â±ï¸ Timeout per project: 30 minutes")
    
    response = input(f"\nç»§ç»­å¹¶è¡Œè¿è¡Œè¿™ {len(selected_projects)} ä¸ªé¡¹ç›®? (y/N): ")
    if response.lower() != 'y':
        print("âŒ Cancelled by user")
        sys.exit(0)
    
    # å¼€å§‹å¹¶è¡Œæ‰¹é‡è¿è¡Œ
    results = run_parallel_translations(selected_projects, base_dir, max_iterations, num_processes)
    
    # ä¿å­˜ç»“æœ
    save_results(results, "batch_results")
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    success_count = len([r for r in results if r['return_code'] == 0])
    print(f"\nğŸ“Š Final Stats: {success_count}/{len(results)} projects succeeded ({success_count/len(results)*100:.1f}%)")
    
    # æ˜¾ç¤ºå„çŠ¶æ€çš„é¡¹ç›®æ•°
    status_counts = defaultdict(int)
    for result in results:
        if result['return_code'] == 0:
            status_counts['Success'] += 1
        elif result['return_code'] == 1:
            status_counts['Failed'] += 1
        elif result['return_code'] == 2:
            status_counts['Timeout'] += 1
        else:
            status_counts['Error'] += 1
    
    print(f"ğŸ“ˆ Breakdown:")
    for status, count in status_counts.items():
        print(f"   {status}: {count}")

if __name__ == "__main__":
    main()